# Функции потерь `nnf_xxx()`
Как правило, нейронные сети применяются для решения одной из двух задвч:
* _**предсказание численного значения (регрессия)**_  
Используются функции потерь:
  * `nnf_mse_loss()` – _mean squared error_ (_MSE_)
  * `nnf_l1_loss()` – _mean absolute error (MAE)_
  * `nn_smooth_l1_loss()` – для небольших отклонений использует _MSE_, а для ограничения ошибки при больших отклонениях – _MAE_.
* _**предсказание вероятности (классификация)**_  
Используются функции потерь:
  * `nnf_binary_cross_entropy_with_logits()` (_BCeL_) — аргументом является непрерывная числовая переменная (добавляет стабильность при вычислениях)
  * `nnf_cross_entropy()` (_Ce_)
  * `nnf_binary_cross_entropy()` (_BCE_) – аргументом являются вероятности, полученные посредством сигмоиды
  * `nnf_nll_loss()` (_Nll_).

Для преобразования непрерывной числовой переменной в вероятность используется сигмоида `nnf_sigmoid()`, которая определена на всей числовой прямой, а множество ее значений лежит в интервале (0; 1). Если модель выдает необработанные оценки вероятностей, то предпочтительнее использовать _BCeL_, а не сигмоиду + _BCE_, поскольку первая добавляет дополнительную численную стабильность в процесс расчета.

В случае многоклассовой классификации необработанные оценки представляют собой двумерный тензор (строки – наблюдения, столбцы – классы). Для преобразования его в вероятности может использоваться функция `nnf_softmax()`. При этом, как и в случае бинарной классификации, нет необходимости иметь в конце сети `nnf_softmax()`, – предпочтительнее использовать `nnf_cross_entropy()` для необработанных оценок вероятности.

|Функция потерь|Бинарные данные|Многоклассовые данные|Необработанные оценки вероятности|Вероятности|Логарифмы вероятностей|
|:----|:---:|:---:|:---:|:---:|:---:|
|_BCeL_|+| |+| | |
|_Ce_  | |+|+| | |
|_BCE_ |+| | |+| |
|_Nll_ | |+| | |+|

Функции потерь могут быть заданы как непосредственно функцией `nnf_xxx()`, так и объектом `nn_xxx()`.  
Например, среднеквадратичная функция потерь задается как `nnf_mse_loss(tensor1, tensor2)`. В тоже время может быть создан объект MSE `l <- nn_mse_loss()` и уже затем применяться к соответствующим тензорам: `l(tensor1, tensor2)`.
