# Автоматическое дифференцирование
Чтобы тензор, участвующий в расчетах выражения, мог накапливать информацию для расчета автоградиентов, необходимо при его создании указать параметр `requires_grad = TRUE`. Все промежуточные тензоры, учасвующие в расчете выражения будут наследовать этот параметр и не требуют его указания при своем создании. Каждый такой тензор будет иметь свойство `$requires_grad = TRUE`:
```r
t <- torch_tensor(2, requires_grad = TRUE)
```
Если при расчете был получен тензор `result`, то вызов `result$backward()` сделает обратный проход по графу вычислений и произведет расчет градиентов в каждом узле, в том числе и в исходном тензоре (при этом, если на каждом узле при прямом проходе была вызвана функция `$retain_grad()`, то результаты промежуточных узлов будут сохраняться – в противном случае для экономии памяти результаты отбросятся после использования). Чтобы получить значение градиента достаточно обратиться к свойству `t$grad`, которое вернет значение частной производная результата по входному параметру.
