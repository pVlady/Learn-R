# Автоматическое дифференцирование
Чтобы тензор, участвующий в расчетах выражения, мог накапливать информацию для расчета автоградиентов, необходимо при его создании указать параметр `requires_grad = TRUE`. Все промежуточные тензоры, учасвующие в расчете выражения будут наследовать этот параметр и не требуют его указания при своем создании. Каждый такой тензор будет иметь свойство `$requires_grad = TRUE`:
```r
t <- torch_tensor(2, requires_grad = TRUE)
```
Если при расчете был получен тензор `result`, то вызов `result$backward()` сделает обратный проход по графу вычислений и произведет расчет градиентов в каждом узле, в том числе и в исходном тензоре (при этом, если на каждом узле при прямом проходе была вызвана функция `$retain_grad()`, то результаты расчета градиентов для промежуточных узлов будут сохраняться – в противном случае для экономии памяти эти результаты будут отброшены после использования). Чтобы получить значение градиента для тензора узла достаточно обратиться к его свойству `$grad`, которое вернет значение частной производной результата по значениям данного тензора. Как правило, интересуют только значения градиента по значениям входного тензора, находящелгося в начале графа вычислений. Зная эти градиенты, появляется возможность изменить значения исходного тензора в направлении улучшения результата.
